{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.7"
    },
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdKDiKRGnNHi",
        "colab_type": "text"
      },
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NQAnG5losO_",
        "colab_type": "code",
        "outputId": "d344851d-1fbe-46b1-9812-5eaab1245c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "%%shell\n",
        "pip install sk-video"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sk-video\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/dd/3f/ce848b8b2062ad1ccf1449094a740c775f6c761339f411e44f1e090f23a7/sk_video-1.1.10-py2.py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.17.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.4.1)\n",
            "Installing collected packages: sk-video\n",
            "Successfully installed sk-video-1.1.10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWCjjb14nNHm",
        "colab_type": "code",
        "outputId": "a6952149-d946-414b-fac2-026f18fba6eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mv64yernNHw",
        "colab_type": "text"
      },
      "source": [
        "# MiniProject on Deep Reinforcement Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VRIJAtS_nNHx",
        "colab_type": "text"
      },
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5H2jwEenNHy",
        "colab_type": "text"
      },
      "source": [
        "# Context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lhhG7k0nNH1",
        "colab_type": "text"
      },
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnFqEUKAnNH2",
        "colab_type": "text"
      },
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVBOLLFCnNH3",
        "colab_type": "text"
      },
      "source": [
        "### The environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frP90RKtnNH5",
        "colab_type": "text"
      },
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghxnvdZNnNH7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-cq3ojlnNIB",
        "colab_type": "text"
      },
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJwWZoBInNID",
        "colab_type": "text"
      },
      "source": [
        "### The Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUGfHCj_nNIE",
        "colab_type": "text"
      },
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze8T7x1ynNIG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWBoLyJhnNIJ",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9facrFX7nNIK",
        "colab_type": "text"
      },
      "source": [
        "When training, `epsilon` is essential as it weights the exploitation-exploration tradeoff: with probability `epsilon` the Agent explores a random action, otherwise it only applies the policy defined on its previous exploration. \n",
        "\n",
        "When not training, the Agent simply applies the policy. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4mh78xgnNIM",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJnTH9twnNIO",
        "colab_type": "text"
      },
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32jI20nvnNIP",
        "colab_type": "text"
      },
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLNHm9MFnNIQ",
        "colab_type": "text"
      },
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gcCVcIDJnNIS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:  # right\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:  # left\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:  # up\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:  # down\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PyrYRaInNIW",
        "colab_type": "text"
      },
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5T9hyCeKnNIX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=50 # set small when debugging\n",
        "epochs_test=50 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXvUIY6LnNIc",
        "colab_type": "text"
      },
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZjtXiUanNIf",
        "colab_type": "text"
      },
      "source": [
        "The `state` array contains `position` which describes the localisation of the rat at given state by pointing it out by value 1 in the array. Also as the array is padded with 2 more cells on each side to enable the vision of the rat, these cells are set to -1. \n",
        "\n",
        "It also contains the `board` array which describes the state of the board, i.e. the positions and values of the bonuses (cheese) and maluses (poison). A cell containing a bonus or a malus is set to 0 as soon as it is visited by the rat. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XGoVZl8anNIg",
        "colab_type": "text"
      },
      "source": [
        "## Random Agent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ugBdV_BqnNIi",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NKGMnPCnNIj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        action = np.random.randint(5)\n",
        "        return action"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtIm-hqLnNIu",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7o4-5IV-nNIv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        state = env.reset()\n",
        "        game_over = False\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            action = agent.act(state)\n",
        "            prev_state = state \n",
        "            state, reward, game_over = env.act(action)\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "        \n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCeSkh2UnNIz",
        "colab_type": "code",
        "outputId": "d7260fd0-b6db-4f44-8e29-810e992501dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 9.5/13.0. Average score (-3.5)\n",
            "Win/lose count 7.0/13.0. Average score (-4.75)\n",
            "Win/lose count 7.0/9.0. Average score (-3.8333333333333335)\n",
            "Win/lose count 9.5/8.0. Average score (-2.5)\n",
            "Win/lose count 7.5/18.0. Average score (-4.1)\n",
            "Final score: -4.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WqqfTKYinNI3",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezlhqZUCnNI4",
        "colab_type": "text"
      },
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TqH27nYdnNI6",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alLhbP-QnNI6",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j054q4bYnNI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        if len(self.memory) == self.max_memory:\n",
        "            self.memory.pop(0)\n",
        "        self.memory.append(m)\n",
        "\n",
        "    def random_access(self):\n",
        "        index = np.random.randint(len(self.memory))\n",
        "        return self.memory[index]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZPR2HK5nNI9",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zoc4QL-tnNI_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGvffU64nNJD",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXO0sL5mnNJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        pred = self.model.predict(s.reshape((1, 5, 5, self.n_state)))\n",
        "        return np.argmax(pred, axis=1)\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        \n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        \n",
        "        for i in range(self.batch_size):\n",
        "            random_state = self.memory.random_access()\n",
        "            s, n_s, a, r, game_over = random_state\n",
        "            input_states[i, :, :, :] = s\n",
        "            \n",
        "            if game_over_:\n",
        "                target_q[i][a] = r \n",
        "            else:\n",
        "                max_q = np.max(self.model.predict(n_s.reshape((1, 5, 5, self.n_state))), axis=1)\n",
        "                target_q[i][a] = r + self.discount*max_q\n",
        "        \n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        n_layers = 3\n",
        "        model = Sequential()\n",
        "        model.add(Flatten(input_shape=(5, 5, self.n_state)))\n",
        "        for i in range(n_layers):\n",
        "            model.add(Dense(32, activation='relu'))\n",
        "        model.add(Dense(self.n_action, activation='softmax'))\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnwrUS6inNJH",
        "colab_type": "code",
        "outputId": "b4d28162-358e-4025-bb2c-108f64ae5a70",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=.01, epsilon = 0.5, memory_size=2000, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train40.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/050 | Loss 0.0629 | Win/lose count 10.5/7.0 (3.5)\n",
            "Epoch 001/050 | Loss 0.0645 | Win/lose count 2.5/15.0 (-12.5)\n",
            "Epoch 002/050 | Loss 0.1003 | Win/lose count 8.5/9.0 (-0.5)\n",
            "Epoch 003/050 | Loss 0.0658 | Win/lose count 2.5/8.0 (-5.5)\n",
            "Epoch 004/050 | Loss 0.0894 | Win/lose count 4.5/13.0 (-8.5)\n",
            "Epoch 005/050 | Loss 0.0756 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 006/050 | Loss 0.1156 | Win/lose count 6.5/9.0 (-2.5)\n",
            "Epoch 007/050 | Loss 0.0665 | Win/lose count 4.5/14.0 (-9.5)\n",
            "Epoch 008/050 | Loss 0.0920 | Win/lose count 4.5/9.0 (-4.5)\n",
            "Epoch 009/050 | Loss 0.0792 | Win/lose count 1.5/5.0 (-3.5)\n",
            "Epoch 010/050 | Loss 0.0797 | Win/lose count 3.0/0 (3.0)\n",
            "Epoch 011/050 | Loss 0.0784 | Win/lose count 3.5/8.0 (-4.5)\n",
            "Epoch 012/050 | Loss 0.0825 | Win/lose count 4.5/9.0 (-4.5)\n",
            "Epoch 013/050 | Loss 0.0693 | Win/lose count 6.5/3.0 (3.5)\n",
            "Epoch 014/050 | Loss 0.0693 | Win/lose count 0.5/5.0 (-4.5)\n",
            "Epoch 015/050 | Loss 0.0701 | Win/lose count 5.0/5.0 (0.0)\n",
            "Epoch 016/050 | Loss 0.0700 | Win/lose count 4.5/5.0 (-0.5)\n",
            "Epoch 017/050 | Loss 0.0812 | Win/lose count 1.0/7.0 (-6.0)\n",
            "Epoch 018/050 | Loss 0.0713 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 019/050 | Loss 0.0959 | Win/lose count 4.5/10.0 (-5.5)\n",
            "Epoch 020/050 | Loss 0.0837 | Win/lose count 3.5/11.0 (-7.5)\n",
            "Epoch 021/050 | Loss 0.0831 | Win/lose count 4.0/5.0 (-1.0)\n",
            "Epoch 022/050 | Loss 0.1163 | Win/lose count 2.0/7.0 (-5.0)\n",
            "Epoch 023/050 | Loss 0.0822 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 024/050 | Loss 0.0688 | Win/lose count 2.0/2.0 (0.0)\n",
            "Epoch 025/050 | Loss 0.1109 | Win/lose count 4.5/4.0 (0.5)\n",
            "Epoch 026/050 | Loss 0.0915 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 027/050 | Loss 0.0697 | Win/lose count 9.0/10.0 (-1.0)\n",
            "Epoch 028/050 | Loss 0.0683 | Win/lose count 6.0/6.0 (0.0)\n",
            "Epoch 029/050 | Loss 0.1024 | Win/lose count 2.5/4.0 (-1.5)\n",
            "Epoch 030/050 | Loss 0.0675 | Win/lose count 2.5/8.0 (-5.5)\n",
            "Epoch 031/050 | Loss 0.0814 | Win/lose count 5.5/4.0 (1.5)\n",
            "Epoch 032/050 | Loss 0.0699 | Win/lose count 3.5/5.0 (-1.5)\n",
            "Epoch 033/050 | Loss 0.0811 | Win/lose count 7.0/7.0 (0.0)\n",
            "Epoch 034/050 | Loss 0.0709 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 035/050 | Loss 0.0713 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 036/050 | Loss 0.1034 | Win/lose count 5.0/10.0 (-5.0)\n",
            "Epoch 037/050 | Loss 0.0712 | Win/lose count 8.5/14.0 (-5.5)\n",
            "Epoch 038/050 | Loss 0.0702 | Win/lose count 5.5/6.0 (-0.5)\n",
            "Epoch 039/050 | Loss 0.0924 | Win/lose count 3.0/4.0 (-1.0)\n",
            "Epoch 040/050 | Loss 0.0707 | Win/lose count 3.5/7.0 (-3.5)\n",
            "Epoch 041/050 | Loss 0.0700 | Win/lose count 4.5/6.0 (-1.5)\n",
            "Epoch 042/050 | Loss 0.0841 | Win/lose count 6.0/8.0 (-2.0)\n",
            "Epoch 043/050 | Loss 0.0677 | Win/lose count 4.5/10.0 (-5.5)\n",
            "Epoch 044/050 | Loss 0.0808 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 045/050 | Loss 0.0704 | Win/lose count 6.0/11.0 (-5.0)\n",
            "Epoch 046/050 | Loss 0.0967 | Win/lose count 5.0/4.0 (1.0)\n",
            "Epoch 047/050 | Loss 0.1051 | Win/lose count 4.0/6.0 (-2.0)\n",
            "Epoch 048/050 | Loss 0.0843 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 049/050 | Loss 0.0807 | Win/lose count 5.0/7.0 (-2.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzAcxhdfnNJJ",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDqgLXI3nNJK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        n_layers = 2\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(16, (2, 2), input_shape=(5, 5, self.n_state), activation='relu'))\n",
        "        model.add(Conv2D(32, (2,2), activation='relu'))\n",
        "        model.add(Flatten())\n",
        "        #for i in range(n_layers):\n",
        "         #   model.add(Dense(32, activation='relu'))\n",
        "        model.add(Dense(self.n_action))\n",
        "\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olLqYjcinNJP",
        "colab_type": "code",
        "outputId": "6cc14352-a1e2-4a39-ef42-12fb3517a09e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')\n",
        "HTML(display_videos('cnn_train40.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/050 | Loss 0.0014 | Win/lose count 2.0/1.0 (1.0)\n",
            "Epoch 001/050 | Loss 0.0119 | Win/lose count 3.5/4.0 (-0.5)\n",
            "Epoch 002/050 | Loss 0.0039 | Win/lose count 4.5/8.0 (-3.5)\n",
            "Epoch 003/050 | Loss 0.0086 | Win/lose count 1.0/2.0 (-1.0)\n",
            "Epoch 004/050 | Loss 0.0101 | Win/lose count 2.5/2.0 (0.5)\n",
            "Epoch 005/050 | Loss 0.0015 | Win/lose count 2.0/2.0 (0.0)\n",
            "Epoch 006/050 | Loss 0.0012 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 007/050 | Loss 0.0141 | Win/lose count 1.5/0 (1.5)\n",
            "Epoch 008/050 | Loss 0.0028 | Win/lose count 1.5/2.0 (-0.5)\n",
            "Epoch 009/050 | Loss 0.0091 | Win/lose count 6.0/5.0 (1.0)\n",
            "Epoch 010/050 | Loss 0.0010 | Win/lose count 4.0/7.0 (-3.0)\n",
            "Epoch 011/050 | Loss 0.0070 | Win/lose count 1.5/4.0 (-2.5)\n",
            "Epoch 012/050 | Loss 0.0088 | Win/lose count 6.0/6.0 (0.0)\n",
            "Epoch 013/050 | Loss 0.0038 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 014/050 | Loss 0.0024 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 015/050 | Loss 0.0043 | Win/lose count 6.0/0 (6.0)\n",
            "Epoch 016/050 | Loss 0.0034 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 017/050 | Loss 0.0178 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 018/050 | Loss 0.0053 | Win/lose count 4.5/1.0 (3.5)\n",
            "Epoch 019/050 | Loss 0.0026 | Win/lose count 5.0/2.0 (3.0)\n",
            "Epoch 020/050 | Loss 0.0015 | Win/lose count 3.5/0 (3.5)\n",
            "Epoch 021/050 | Loss 0.0013 | Win/lose count 3.5/7.0 (-3.5)\n",
            "Epoch 022/050 | Loss 0.0027 | Win/lose count 4.5/3.0 (1.5)\n",
            "Epoch 023/050 | Loss 0.0040 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 024/050 | Loss 0.0053 | Win/lose count 3.0/1.0 (2.0)\n",
            "Epoch 025/050 | Loss 0.0015 | Win/lose count 7.0/1.0 (6.0)\n",
            "Epoch 026/050 | Loss 0.0031 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 027/050 | Loss 0.0010 | Win/lose count 5.0/5.0 (0.0)\n",
            "Epoch 028/050 | Loss 0.0030 | Win/lose count 8.0/5.0 (3.0)\n",
            "Epoch 029/050 | Loss 0.0105 | Win/lose count 5.0/3.0 (2.0)\n",
            "Epoch 030/050 | Loss 0.0017 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 031/050 | Loss 0.0037 | Win/lose count 2.0/0 (2.0)\n",
            "Epoch 032/050 | Loss 0.0011 | Win/lose count 2.5/3.0 (-0.5)\n",
            "Epoch 033/050 | Loss 0.0032 | Win/lose count 7.0/0 (7.0)\n",
            "Epoch 034/050 | Loss 0.0057 | Win/lose count 6.0/4.0 (2.0)\n",
            "Epoch 035/050 | Loss 0.0024 | Win/lose count 3.5/5.0 (-1.5)\n",
            "Epoch 036/050 | Loss 0.0033 | Win/lose count 3.0/3.0 (0.0)\n",
            "Epoch 037/050 | Loss 0.0026 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 038/050 | Loss 0.0017 | Win/lose count 2.0/3.0 (-1.0)\n",
            "Epoch 039/050 | Loss 0.0112 | Win/lose count 3.5/2.0 (1.5)\n",
            "Epoch 040/050 | Loss 0.0095 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 041/050 | Loss 0.0014 | Win/lose count 4.0/2.0 (2.0)\n",
            "Epoch 042/050 | Loss 0.0023 | Win/lose count 4.5/0 (4.5)\n",
            "Epoch 043/050 | Loss 0.0107 | Win/lose count 1.0/1.0 (0.0)\n",
            "Epoch 044/050 | Loss 0.0013 | Win/lose count 5.5/2.0 (3.5)\n",
            "Epoch 045/050 | Loss 0.0017 | Win/lose count 1.0/8.0 (-7.0)\n",
            "Epoch 046/050 | Loss 0.0100 | Win/lose count 2.0/2.0 (0.0)\n",
            "Epoch 047/050 | Loss 0.0011 | Win/lose count 5.0/0 (5.0)\n",
            "Epoch 048/050 | Loss 0.0015 | Win/lose count 6.0/4.0 (2.0)\n",
            "Epoch 049/050 | Loss 0.0014 | Win/lose count 4.5/2.0 (2.5)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UF99wVImnNJS",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MHsSvfwMnNJT",
        "colab_type": "code",
        "outputId": "e5a20580-2a12-444e-f43f-5dcae929c017",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.7)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 5.5/3.0. Average score (2.5)\n",
            "Win/lose count 4.0/3.0. Average score (1.75)\n",
            "Win/lose count 4.0/2.0. Average score (1.8333333333333333)\n",
            "Win/lose count 5.0/2.0. Average score (2.125)\n",
            "Win/lose count 4.5/3.0. Average score (2.0)\n",
            "Win/lose count 6.5/7.0. Average score (1.5833333333333333)\n",
            "Win/lose count 5.0/0. Average score (2.0714285714285716)\n",
            "Win/lose count 8.0/2.0. Average score (2.5625)\n",
            "Win/lose count 8.0/3.0. Average score (2.8333333333333335)\n",
            "Win/lose count 3.0/1.0. Average score (2.75)\n",
            "Win/lose count 5.0/1.0. Average score (2.8636363636363638)\n",
            "Win/lose count 5.5/4.0. Average score (2.75)\n",
            "Win/lose count 4.0/6.0. Average score (2.3846153846153846)\n",
            "Win/lose count 8.5/5.0. Average score (2.4642857142857144)\n",
            "Win/lose count 6.5/3.0. Average score (2.533333333333333)\n",
            "Win/lose count 5.5/0. Average score (2.71875)\n",
            "Win/lose count 4.0/2.0. Average score (2.676470588235294)\n",
            "Win/lose count 3.5/2.0. Average score (2.611111111111111)\n",
            "Win/lose count 4.0/2.0. Average score (2.5789473684210527)\n",
            "Win/lose count 5.5/4.0. Average score (2.525)\n",
            "Win/lose count 6.0/4.0. Average score (2.5)\n",
            "Win/lose count 5.0/2.0. Average score (2.522727272727273)\n",
            "Win/lose count 6.0/3.0. Average score (2.5434782608695654)\n",
            "Win/lose count 3.0/2.0. Average score (2.4791666666666665)\n",
            "Win/lose count 5.0/5.0. Average score (2.38)\n",
            "Win/lose count 5.5/2.0. Average score (2.423076923076923)\n",
            "Win/lose count 2.5/4.0. Average score (2.2777777777777777)\n",
            "Win/lose count 7.0/3.0. Average score (2.3392857142857144)\n",
            "Win/lose count 4.0/1.0. Average score (2.3620689655172415)\n",
            "Win/lose count 5.5/1.0. Average score (2.433333333333333)\n",
            "Win/lose count 5.5/7.0. Average score (2.306451612903226)\n",
            "Win/lose count 6.5/2.0. Average score (2.375)\n",
            "Win/lose count 4.5/4.0. Average score (2.3181818181818183)\n",
            "Win/lose count 9.0/1.0. Average score (2.485294117647059)\n",
            "Win/lose count 8.5/1.0. Average score (2.6285714285714286)\n",
            "Win/lose count 7.0/4.0. Average score (2.638888888888889)\n",
            "Win/lose count 4.5/1.0. Average score (2.6621621621621623)\n",
            "Win/lose count 6.0/0. Average score (2.75)\n",
            "Win/lose count 5.5/5.0. Average score (2.6923076923076925)\n",
            "Win/lose count 7.0/6.0. Average score (2.65)\n",
            "Win/lose count 7.0/7.0. Average score (2.5853658536585367)\n",
            "Win/lose count 5.0/2.0. Average score (2.5952380952380953)\n",
            "Win/lose count 3.5/1.0. Average score (2.5930232558139537)\n",
            "Win/lose count 10.5/1.0. Average score (2.75)\n",
            "Win/lose count 4.5/5.0. Average score (2.6777777777777776)\n",
            "Win/lose count 7.5/1.0. Average score (2.760869565217391)\n",
            "Win/lose count 10.5/0. Average score (2.925531914893617)\n",
            "Win/lose count 4.5/1.0. Average score (2.9375)\n",
            "Win/lose count 5.5/4.0. Average score (2.9081632653061225)\n",
            "Win/lose count 9.0/4.0. Average score (2.95)\n",
            "Final score: 2.95\n",
            "Test of the FC\n",
            "Win/lose count 2.0/5.0. Average score (-3.0)\n",
            "Win/lose count 10.5/3.0. Average score (2.25)\n",
            "Win/lose count 9.0/5.0. Average score (2.8333333333333335)\n",
            "Win/lose count 9.0/7.0. Average score (2.625)\n",
            "Win/lose count 5.0/3.0. Average score (2.5)\n",
            "Win/lose count 12.0/2.0. Average score (3.75)\n",
            "Win/lose count 9.0/4.0. Average score (3.9285714285714284)\n",
            "Win/lose count 8.5/3.0. Average score (4.125)\n",
            "Win/lose count 3.5/2.0. Average score (3.8333333333333335)\n",
            "Win/lose count 5.0/3.0. Average score (3.65)\n",
            "Win/lose count 8.5/3.0. Average score (3.8181818181818183)\n",
            "Win/lose count 3.0/2.0. Average score (3.5833333333333335)\n",
            "Win/lose count 4.0/2.0. Average score (3.4615384615384617)\n",
            "Win/lose count 6.5/6.0. Average score (3.25)\n",
            "Win/lose count 8.0/4.0. Average score (3.3)\n",
            "Win/lose count 10.0/9.0. Average score (3.15625)\n",
            "Win/lose count 13.0/5.0. Average score (3.4411764705882355)\n",
            "Win/lose count 9.5/5.0. Average score (3.5)\n",
            "Win/lose count 4.5/4.0. Average score (3.3421052631578947)\n",
            "Win/lose count 5.0/7.0. Average score (3.075)\n",
            "Win/lose count 4.0/5.0. Average score (2.880952380952381)\n",
            "Win/lose count 3.5/4.0. Average score (2.727272727272727)\n",
            "Win/lose count 4.0/1.0. Average score (2.739130434782609)\n",
            "Win/lose count 6.0/3.0. Average score (2.75)\n",
            "Win/lose count 5.0/5.0. Average score (2.64)\n",
            "Win/lose count 6.5/4.0. Average score (2.6346153846153846)\n",
            "Win/lose count 7.5/3.0. Average score (2.7037037037037037)\n",
            "Win/lose count 7.0/7.0. Average score (2.607142857142857)\n",
            "Win/lose count 8.0/6.0. Average score (2.586206896551724)\n",
            "Win/lose count 3.0/5.0. Average score (2.433333333333333)\n",
            "Win/lose count 5.0/7.0. Average score (2.2903225806451615)\n",
            "Win/lose count 8.0/9.0. Average score (2.1875)\n",
            "Win/lose count 6.5/6.0. Average score (2.1363636363636362)\n",
            "Win/lose count 8.0/6.0. Average score (2.1323529411764706)\n",
            "Win/lose count 7.5/3.0. Average score (2.2)\n",
            "Win/lose count 13.0/6.0. Average score (2.3333333333333335)\n",
            "Win/lose count 3.5/2.0. Average score (2.310810810810811)\n",
            "Win/lose count 7.5/2.0. Average score (2.3947368421052633)\n",
            "Win/lose count 3.0/2.0. Average score (2.358974358974359)\n",
            "Win/lose count 7.0/2.0. Average score (2.425)\n",
            "Win/lose count 3.5/3.0. Average score (2.3780487804878048)\n",
            "Win/lose count 5.5/2.0. Average score (2.4047619047619047)\n",
            "Win/lose count 5.0/4.0. Average score (2.372093023255814)\n",
            "Win/lose count 4.5/5.0. Average score (2.3068181818181817)\n",
            "Win/lose count 6.0/4.0. Average score (2.3)\n",
            "Win/lose count 9.5/8.0. Average score (2.282608695652174)\n",
            "Win/lose count 9.0/6.0. Average score (2.297872340425532)\n",
            "Win/lose count 9.0/2.0. Average score (2.3958333333333335)\n",
            "Win/lose count 3.0/1.0. Average score (2.3877551020408165)\n",
            "Win/lose count 6.0/7.0. Average score (2.32)\n",
            "Final score: 2.32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0x9YkcXnNJV",
        "colab_type": "code",
        "outputId": "9b9ef32a-0ed1-4f9f-e38b-fe9b3d36368b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "HTML(display_videos('cnn_test10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ul9PKmbLnNJX",
        "colab_type": "code",
        "outputId": "3875f33d-993e-4094-e8cf-3124f349731e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "source": [
        "HTML(display_videos('fc_test10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xMJ7Pyz7nNJb",
        "colab_type": "text"
      },
      "source": [
        "Both agents, especially the CNN one seem to be stuck in some part of the board. Results from CNN are slightly better than the Fully Connected. But it tends to explore less. \n",
        "\n",
        "As temperature increases, the number of cheese increases, so they both explore more and receive better results. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8QUsjiiunNJc",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVf_2ivHnNJc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_explore(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    start_epsilon = agent.epsilon\n",
        "    end_epsilon = 0.1\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        # dicrease epsilon\n",
        "        agent.set_epsilon((start_epsilon - end_epsilon)*e/epoch)\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose - reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "        \n",
        "class EnvironmentExploring(Environment):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size, grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def act(self, action, train=False):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:  # right\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:  # left\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:  # up\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:  # down\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        if train:\n",
        "            reward = - self.malus_position[self.x, self.y]\n",
        "        else:\n",
        "            reward = 0\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "        reward = reward + self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size, 1), \n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1), \n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "    \n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size, 1), \n",
        "                                self.board.reshape(self.grid_size, self.grid_size,1), \n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mamm7WEZnNJe",
        "colab_type": "code",
        "outputId": "398b32d5-f821-4111-d5a3-a5ad683f65a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Training\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent, env, epochs_train, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/050 | Loss 0.0028 | Win/lose count 4.5/23.900000000000077 (-19.400000000000077)\n",
            "Epoch 001/050 | Loss 0.0149 | Win/lose count 4.0/19.90000000000002 (-15.90000000000002)\n",
            "Epoch 002/050 | Loss 0.0176 | Win/lose count 6.5/19.900000000000006 (-13.400000000000006)\n",
            "Epoch 003/050 | Loss 0.0093 | Win/lose count 1.5/22.000000000000046 (-20.500000000000046)\n",
            "Epoch 004/050 | Loss 0.0058 | Win/lose count 3.5/19.200000000000003 (-15.700000000000003)\n",
            "Epoch 005/050 | Loss 0.0051 | Win/lose count 4.5/19.30000000000001 (-14.800000000000011)\n",
            "Epoch 006/050 | Loss 0.0020 | Win/lose count 4.0/19.40000000000001 (-15.40000000000001)\n",
            "Epoch 007/050 | Loss 0.0136 | Win/lose count 3.5/22.000000000000032 (-18.500000000000032)\n",
            "Epoch 008/050 | Loss 0.0023 | Win/lose count 1.0/20.40000000000002 (-19.40000000000002)\n",
            "Epoch 009/050 | Loss 0.0041 | Win/lose count 8.0/21.0 (-13.0)\n",
            "Epoch 010/050 | Loss 0.0021 | Win/lose count 6.5/19.39999999999999 (-12.899999999999991)\n",
            "Epoch 011/050 | Loss 0.0119 | Win/lose count 4.0/26.200000000000053 (-22.200000000000053)\n",
            "Epoch 012/050 | Loss 0.0110 | Win/lose count 3.5/21.20000000000003 (-17.70000000000003)\n",
            "Epoch 013/050 | Loss 0.0109 | Win/lose count 11.0/24.900000000000073 (-13.900000000000073)\n",
            "Epoch 014/050 | Loss 0.0055 | Win/lose count 2.5/19.0 (-16.5)\n",
            "Epoch 015/050 | Loss 0.0093 | Win/lose count 3.5/19.900000000000013 (-16.400000000000013)\n",
            "Epoch 016/050 | Loss 0.0055 | Win/lose count 9.5/20.000000000000007 (-10.500000000000007)\n",
            "Epoch 017/050 | Loss 0.0143 | Win/lose count 10.0/23.30000000000008 (-13.300000000000079)\n",
            "Epoch 018/050 | Loss 0.0125 | Win/lose count 1.0/21.300000000000033 (-20.300000000000033)\n",
            "Epoch 019/050 | Loss 0.0148 | Win/lose count 3.5/18.499999999999993 (-14.999999999999993)\n",
            "Epoch 020/050 | Loss 0.0118 | Win/lose count 2.5/18.699999999999996 (-16.199999999999996)\n",
            "Epoch 021/050 | Loss 0.0056 | Win/lose count 5.0/18.699999999999996 (-13.699999999999996)\n",
            "Epoch 022/050 | Loss 0.0085 | Win/lose count 4.0/18.39999999999999 (-14.399999999999991)\n",
            "Epoch 023/050 | Loss 0.0042 | Win/lose count 10.5/18.49999999999998 (-7.999999999999979)\n",
            "Epoch 024/050 | Loss 0.0059 | Win/lose count 3.0/18.9 (-15.899999999999999)\n",
            "Epoch 025/050 | Loss 0.0042 | Win/lose count 2.5/21.20000000000004 (-18.70000000000004)\n",
            "Epoch 026/050 | Loss 0.0039 | Win/lose count 7.0/19.600000000000016 (-12.600000000000016)\n",
            "Epoch 027/050 | Loss 0.0018 | Win/lose count 19.0/16.299999999999965 (2.700000000000035)\n",
            "Epoch 028/050 | Loss 0.0124 | Win/lose count 9.0/18.79999999999999 (-9.79999999999999)\n",
            "Epoch 029/050 | Loss 0.0095 | Win/lose count 16.0/19.500000000000007 (-3.500000000000007)\n",
            "Epoch 030/050 | Loss 0.0046 | Win/lose count 5.0/20.30000000000002 (-15.300000000000018)\n",
            "Epoch 031/050 | Loss 0.0063 | Win/lose count 8.0/20.799999999999983 (-12.799999999999983)\n",
            "Epoch 032/050 | Loss 0.0070 | Win/lose count 10.5/20.700000000000035 (-10.200000000000035)\n",
            "Epoch 033/050 | Loss 0.0140 | Win/lose count 4.0/19.800000000000015 (-15.800000000000015)\n",
            "Epoch 034/050 | Loss 0.0058 | Win/lose count 8.5/17.499999999999982 (-8.999999999999982)\n",
            "Epoch 035/050 | Loss 0.0083 | Win/lose count 11.5/18.29999999999999 (-6.79999999999999)\n",
            "Epoch 036/050 | Loss 0.0044 | Win/lose count 3.5/19.400000000000006 (-15.900000000000006)\n",
            "Epoch 037/050 | Loss 0.0117 | Win/lose count 17.0/17.599999999999987 (-0.5999999999999872)\n",
            "Epoch 038/050 | Loss 0.0063 | Win/lose count 13.0/18.7 (-5.699999999999999)\n",
            "Epoch 039/050 | Loss 0.0055 | Win/lose count 10.5/17.89999999999999 (-7.3999999999999915)\n",
            "Epoch 040/050 | Loss 0.0136 | Win/lose count 5.0/21.400000000000034 (-16.400000000000034)\n",
            "Epoch 041/050 | Loss 0.0143 | Win/lose count 8.5/19.100000000000005 (-10.600000000000005)\n",
            "Epoch 042/050 | Loss 0.0149 | Win/lose count 0.5/19.900000000000013 (-19.400000000000013)\n",
            "Epoch 043/050 | Loss 0.0194 | Win/lose count 6.5/20.60000000000001 (-14.100000000000009)\n",
            "Epoch 044/050 | Loss 0.0054 | Win/lose count 16.5/13.999999999999966 (2.5000000000000338)\n",
            "Epoch 045/050 | Loss 0.0040 | Win/lose count 8.5/18.099999999999994 (-9.599999999999994)\n",
            "Epoch 046/050 | Loss 0.0075 | Win/lose count 12.0/19.800000000000015 (-7.800000000000015)\n",
            "Epoch 047/050 | Loss 0.0053 | Win/lose count 18.0/17.299999999999983 (0.700000000000017)\n",
            "Epoch 048/050 | Loss 0.0242 | Win/lose count 17.5/20.000000000000032 (-2.500000000000032)\n",
            "Epoch 049/050 | Loss 0.0145 | Win/lose count 19.0/14.79999999999997 (4.2000000000000295)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wwW2TffdnNJj",
        "colab_type": "code",
        "outputId": "02a599f7-2b10-4af0-9d93-6d3bc668fd56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore10.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 2.5/0. Average score (2.5)\n",
            "Win/lose count 8.5/1.0. Average score (5.0)\n",
            "Win/lose count 2.5/0. Average score (4.166666666666667)\n",
            "Win/lose count 21.5/2.0. Average score (8.0)\n",
            "Win/lose count 3.0/0. Average score (7.0)\n",
            "Win/lose count 14.0/5.0. Average score (7.333333333333333)\n",
            "Win/lose count 8.0/0. Average score (7.428571428571429)\n",
            "Win/lose count 2.0/1.0. Average score (6.625)\n",
            "Win/lose count 5.5/4.0. Average score (6.055555555555555)\n",
            "Win/lose count 6.5/0. Average score (6.1)\n",
            "Win/lose count 25.0/2.0. Average score (7.636363636363637)\n",
            "Win/lose count 3.0/0. Average score (7.25)\n",
            "Win/lose count 23.0/6.0. Average score (8.0)\n",
            "Win/lose count 10.5/3.0. Average score (7.964285714285714)\n",
            "Win/lose count 14.0/1.0. Average score (8.3)\n",
            "Win/lose count 4.0/0. Average score (8.03125)\n",
            "Win/lose count 11.5/5.0. Average score (7.9411764705882355)\n",
            "Win/lose count 7.5/1.0. Average score (7.861111111111111)\n",
            "Win/lose count 10.5/2.0. Average score (7.894736842105263)\n",
            "Win/lose count 2.0/2.0. Average score (7.5)\n",
            "Win/lose count 15.5/3.0. Average score (7.738095238095238)\n",
            "Win/lose count 17.5/2.0. Average score (8.090909090909092)\n",
            "Win/lose count 11.0/8.0. Average score (7.869565217391305)\n",
            "Win/lose count 8.0/0. Average score (7.875)\n",
            "Win/lose count 21.0/3.0. Average score (8.28)\n",
            "Win/lose count 3.5/1.0. Average score (8.057692307692308)\n",
            "Win/lose count 5.5/4.0. Average score (7.814814814814815)\n",
            "Win/lose count 2.0/2.0. Average score (7.535714285714286)\n",
            "Win/lose count 3.5/2.0. Average score (7.327586206896552)\n",
            "Win/lose count 9.0/4.0. Average score (7.25)\n",
            "Win/lose count 14.0/2.0. Average score (7.403225806451613)\n",
            "Win/lose count 14.0/1.0. Average score (7.578125)\n",
            "Win/lose count 7.5/1.0. Average score (7.545454545454546)\n",
            "Win/lose count 1.0/0. Average score (7.352941176470588)\n",
            "Win/lose count 3.0/2.0. Average score (7.171428571428572)\n",
            "Win/lose count 8.5/1.0. Average score (7.180555555555555)\n",
            "Win/lose count 14.0/3.0. Average score (7.283783783783784)\n",
            "Win/lose count 3.0/1.0. Average score (7.144736842105263)\n",
            "Win/lose count 15.5/1.0. Average score (7.333333333333333)\n",
            "Win/lose count 14.0/1.0. Average score (7.475)\n",
            "Win/lose count 3.0/0. Average score (7.365853658536586)\n",
            "Win/lose count 18.5/0. Average score (7.630952380952381)\n",
            "Win/lose count 5.0/0. Average score (7.569767441860465)\n",
            "Win/lose count 8.0/1.0. Average score (7.556818181818182)\n",
            "Win/lose count 6.0/2.0. Average score (7.477777777777778)\n",
            "Win/lose count 5.0/1.0. Average score (7.4021739130434785)\n",
            "Win/lose count 18.0/2.0. Average score (7.585106382978723)\n",
            "Win/lose count 7.0/0. Average score (7.572916666666667)\n",
            "Win/lose count 4.5/0. Average score (7.510204081632653)\n",
            "Win/lose count 3.5/1.0. Average score (7.41)\n",
            "Final score: 7.41\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm6PlgyfnNJl",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJq8Xq69nNJl",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gokPj4M_nNJm",
        "colab_type": "text"
      },
      "source": [
        "***"
      ]
    }
  ]
}